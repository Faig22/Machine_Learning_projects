# CycleGAN
## Стилизация фотографий под картины Клода Моне
### Загрузка данных
Ноутбук был создан непосредственно в ***Kaggle*** и поэтому фотографии и картины были взяты оттуда (ссылка на датасет: https://www.kaggle.com/competitions/gan-getting-started/data) и загружены сразу в ноутбук (ссылка на ноутбук: https://www.kaggle.com/code/faig22/cyclegan)

Далее изображения были аугментированы через библиотеку ***albumentations*** 
![image](https://github.com/Faig22/Machine_Learning_projects/assets/95417164/9b099db9-aaf4-4bcf-9006-019e980c343b)

И после были загружены в даталоадер
### Архитектура модели
Модель была взята из статьи (https://arxiv.org/abs/1703.10593)
1. Дискриминатор
   ![image](https://github.com/Faig22/Machine_Learning_projects/assets/95417164/fe95caf1-925e-494e-926e-c3acd5cb9362)

   Он состоит из 5 *conv* слоев. Во всех слоях кроме первого используется ***Instance Norm*** вместо классического ***Batch Norm***. При помощи ***Instance Norm*** можно нивелировать проблему зависимости от контраста в задаче стилизации
   ![image](https://github.com/Faig22/Machine_Learning_projects/assets/95417164/00a85e5e-ad7c-468d-8948-ad337fb2ed7d)

   Дискриминатор принимает на вход изображение размером 256x256 и выводит тензор размером 30x30.
   Каждый нейрон (значение) выходного тензора содержит результат классификации для области входного изображения размером 70x70.
   Обычно дискриминатор GAN выводит одно значение, обозначающее результат классификации входного изображения.
   Возвращая тензор размером 30x30, дискриминатор проверяет, кажется ли каждая область 70x70 (эти области перекрывают друг друга) входного изображения реальной или фальшивой.
   Это эквивалентно выбору вручную каждой из этих областей размером 70х70 и итеративному их исследованию дискриминатором.
   Наконец, результат классификации всего изображения представляет собой среднее значение результатов классификации значений 30x30.

2. Генератор
   ![image](https://github.com/Faig22/Machine_Learning_projects/assets/95417164/cddd9855-7776-454d-a5a2-409ecbeaa7d7)

   Он состоит из *conv* слоев, а также из 9 *residual* слоев. На вход генератор получает фотографию, а на выходе стилизованное изображение
### Обучение
1. Функция потерь
   Суммарная функция потерь состоит из ***adversarial loss*** и ***cycle (consinstency) loss***
   ![image](https://github.com/Faig22/Machine_Learning_projects/assets/95417164/41110d8a-6f57-4ad1-800d-07e5c7c22a28)

2. Гиперпараметры
   
           BATCH_SIZE = 4
           NUM_EPOCHS  = 1
           noise_dim = 100 - размер шума, подаваемый на вход генератора
           SIZE = 256 - размер изображения, который подается на вход дискриминатора и генератора
           learning rate = 0.0002 - обучающий коэффициент у оптимизатора Adam
           beta_1 = 0.5 - коэффициент, используемый для вычисления средних значений градиента у оптимизатора Adam
           beta_2 = 0.999 - коэффициент, используемый для вычисления квадратов градиента у оптимизатора Adam
           CYCLE_LAMBDA = 10 - коэффициент перед cycle_loss


### Результаты
Результаты модели после первой эпохи
![image](https://github.com/Faig22/Machine_Learning_projects/assets/95417164/f1227a2a-ee60-42ec-aca2-1c761f3e50d9)

По графику ниже видно, что генератор обучается, но медленно, поэтому было решено остановить обучение на первой эпохе
![image](https://github.com/Faig22/Machine_Learning_projects/assets/95417164/d141f229-55bb-48b1-bad1-f41fa82d33e6)

