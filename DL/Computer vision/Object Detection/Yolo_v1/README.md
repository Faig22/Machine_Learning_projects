# YOLOv1
## Детекция изображений с помощью модели **YOLOv1**
### Загрузка данных
1. Папки с изображениями были загружены в гугл-диск из открытого источника (https://www.kaggle.com/datasets/aladdinpersson/pascalvoc-yolo)
2. Выгрузка данных непосредственно в ноутбук. 
### Создание датасета
1. Изображения и рамки были помещены в нами созданный датасет **MyDataset**, которая наследуется из **torch.utils.data.Dataset**
2. Изменили размер изображений на *448х448* (как и в оригианьной статье) и переписали в тензоры из **Pytorch**
3. Изображения были загружены в даталоадеры батчами размером *8*
### Создание модели
![image](https://github.com/Faig22/Machine_Learning_projects/assets/95417164/1c121226-00fb-4a37-b33b-ae4c939fbbd6)


1. Модель реализована из статьи (https://arxiv.org/pdf/1506.02640.pdf)
2. **CNN Block**. Блок, состящий из одной свертки, батч-нормализации и функции активации **LeakyRelu**
3. **YOLOv1**. Итоговая модель, состоящая из **CNN** блоков, а необходимые параметры прописаны в **architecture_config**
### Функция потерь
1. Написана метрика **intersection of union** (**IoU**), которая считает площадь пересечения между таргетом и предсказанием
2. **YoloLoss**. Реализована функция потерь из статьи 
![image](https://github.com/Faig22/Machine_Learning_projects/assets/95417164/43f2dc2d-badb-4f9d-93a3-ddfbc58c2f65)

### Обучение 
1. **Non Maximum Suppression**. Метод, позволяющий отобрать лучшие рамки для каждого предсказанного объекта
2. **YOLOv1** обучена на *50* эпохах

![image](https://github.com/Faig22/Machine_Learning_projects/assets/95417164/f4fbbcc6-2336-449d-acff-6d69830798eb)

